{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4d6028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:99% !important;}\n",
       "div.cell.code_cell.rendered{width:99%;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:20pt;}\n",
       "div.output {font-size:18pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:19pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "span.toc-item-num{display:none;}\n",
       "div.text_cell_render ul li{font-size:16pt;padding:5px;}\n",
       "div.CodeMirror-lines > div {padding-left:10px;}\n",
       "table.dataframe{font-size:19px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:99% !important;}\n",
    "div.cell.code_cell.rendered{width:99%;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:20pt;}\n",
    "div.output {font-size:18pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:19pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "span.toc-item-num{display:none;}\n",
    "div.text_cell_render ul li{font-size:16pt;padding:5px;}\n",
    "div.CodeMirror-lines > div {padding-left:10px;}\n",
    "table.dataframe{font-size:19px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a161272d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAACxElEQVR4nL3WT6hVVRTH8c++9/0xe2JIfxTKyCz8MwqClAgUa5ATyUGINpLSWaBDHdTQiSMHQg0LMQmLJkGBFpgTqUGIIiH+QZQMffXM9/Bd790O9r7P4/Gcc5/4cMPiwj53r+9ae6392zvEGD3J0ZrtH0MIYS6AoSnDEMIwRrEAI+hgApMxxt6cAUMILSzCaqzJv2P4BydxAtfQRQ/d2QbwEDCE0MZyfIQP8QqG8ueIm/gRf+IObuM8zuFGjLHTSIwxzphU0xX4Ev9lQJV1C9bBdXyFdzC/6LNsRVjI2RzEZAOszu7id2zB82gPAj6HfQ2w3iygXVzFfryJkUog5uETqQPrHE3hf0wPgPZybX/BegyXyqaFlfijxsG01CQ78TGO5JpND8i6g++xDK0icBRba7ayg6N4QzqHI1iCt7ENX2R4HXQcm4tZks7Xnrxt5a05kWsxVGqugDYW41OcrVjfb6S9GOuvb+XFYx4ePfyA0zHGu/3JeH90c3ZfYxd+rfDRklRquDjRy5FUaWXIkVaOrC7jGfZz9lUe3eJ8Hzhe4biN9/F6lro6aMR8vFYRdMS/OaEZYAeXpaYpj7ewAy/VQbMULpNUpgycwiWpo2eAXZzBXxX+5kmauh0v1FxRT+E9vFzx7Yqks/e3OnfeGHbjlur2voHP8KIHO3YU63LA5TPZk2Ty2Sql6evoIfVKMolvsDFnsxjv4ifVR+ImNhUDLGvpkFSzY1KR6yTu7wz5DhdqYD18i6W14p2hI3mLfqtxNFu7iA8w2ggs1GVDhtZl2mQT+Fy6fcJAYOH2WCsJ9dQjwG7hQO6HVqXv2ps5ydFSSbbOar4dutJZ3pvXVMJijANfbSFnu0rquA14FQslJepfuMdxGKcwERucNgIL4Daelp4OS/BMDuSO9Hq7gPEs6M2+HuXlnTN+QNCbsnls4FyMe921bvvDKtJtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(28, 28, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "c0 = Image.open('data/test/0/1.png')\n",
    "display(c0)\n",
    "c0_numpy = np.array(c0)\n",
    "c0_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ae8ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0_numpy[:, :, :-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93769e1c",
   "metadata": {},
   "source": [
    "# 1. CNN\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de5b3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from PIL import Image\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aacb201e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circle = Image.open('data/handwriting/handwriting_shape/train/circle/circle003.png')\n",
    "np.array(circle).shape\n",
    "# 모든 이미지의 shape이 같을 필요는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b511582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 생성하기 학습훈련셋 : data/handwriting/handwriting_shape/train/*\n",
    "                #   테스트셋 :  data/handwriting/handwriting_shape/test/*\n",
    "train_datagen = ImageDataGenerator(rescale=1./255) # 0~1사이의 값으로 스케일 조정\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    'data/handwriting/handwriting_shape/train',  # train 아래 폴더명이 라벨\n",
    "    target_size=(24,24),      # 넘파이 배열의 이미지 크기 조정\n",
    "    class_mode='categorical', # 원핫인코딩 형식으로 반환\n",
    "    batch_size=3              # 한번에 반환할 이미지와 라벨 수\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    'data/handwriting/handwriting_shape/test',\n",
    "    target_size=(24,24),\n",
    "    class_mode='categorical',\n",
    "    batch_size=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f0204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595cb647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d166b799",
   "metadata": {},
   "source": [
    "# 2. 데이터 증강을 통한 CNN accuracy 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59324160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
